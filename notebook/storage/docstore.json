{"docstore/metadata": {"1fe2137f-4d88-4026-923d-2090b6b3101b": {"doc_hash": "652e8bcfe6ee724f855f0865498aba23a0cf6cbb2c2d46db33d5377045c304d2"}, "bc8b2cca-85cc-49de-879e-7c1930899b91": {"doc_hash": "652e8bcfe6ee724f855f0865498aba23a0cf6cbb2c2d46db33d5377045c304d2", "ref_doc_id": "1fe2137f-4d88-4026-923d-2090b6b3101b"}}, "docstore/data": {"bc8b2cca-85cc-49de-879e-7c1930899b91": {"__data__": {"id_": "bc8b2cca-85cc-49de-879e-7c1930899b91", "embedding": null, "metadata": {"page_label": "1", "file_name": "Danyal-Alam-CV-Resume (2).pdf", "file_path": "d:\\GenAi\\QAsystem\\notebook\\..\\data\\Danyal-Alam-CV-Resume (2).pdf", "file_type": "application/pdf", "file_size": 108742, "creation_date": "2024-09-28", "last_modified_date": "2024-09-19"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1fe2137f-4d88-4026-923d-2090b6b3101b", "node_type": "4", "metadata": {"page_label": "1", "file_name": "Danyal-Alam-CV-Resume (2).pdf", "file_path": "d:\\GenAi\\QAsystem\\notebook\\..\\data\\Danyal-Alam-CV-Resume (2).pdf", "file_type": "application/pdf", "file_size": 108742, "creation_date": "2024-09-28", "last_modified_date": "2024-09-19"}, "hash": "652e8bcfe6ee724f855f0865498aba23a0cf6cbb2c2d46db33d5377045c304d2", "class_name": "RelatedNodeInfo"}}, "text": "Danyal Alam\ndanyalalam514@gmail.com 03175193965 linkedin.com/in/danyal-alam-272593312 \ngithub.com/Danyalalam \nSKILLS\nLanguages \u2014 Python, SQL, HTML\nFrameworks \u2014 Tensorflow/Keras, PyTorch, Pandas, NumPy, NLTK\nMLOps \u2014 Git, Docker, MLflow, DVC, BentoML, CI/CD pipelines, GitHub Actions, RESTful APIs\nCloud Technologies & Databases \u2014 Microsoft Azure, AWS\u00a0\u00a0MySQL , MongoDB\nPROJECTS\nProduction Grade Machine Learning Project: | MongoDB,AWS,Docker,Git,CI/CD,FastApi\nVisa Approval Prediction:\n\u2022End-to-End Pipeline: Built a full machine learning pipeline from data ingestion (via MongoDB) to cloud deployment \nusing Docker and AWS services (EC2, S3, ECR).\n\u2022Model Management: Trained multiple models, evaluated them using Evidently AI for data drift detection, and pushed \nthe best model to S3 for production.\n\u2022CI/CD Integration: Implemented automated CI/CD workflows with GitHub Actions and Dockerized FastApi applicatoin \nfor seamless deployment on AWS, ensuring scalability and reliability.\nEnd TO End Chest Cancer Classification with Mlops(DL): | CNN,Azure,CI/CD,Docker,Git,Flask\n\u2022Developed An End-to-End Deep Learning Pipeline : Designed and implemented a modular pipeline for chest cancer \ndetection using CNN, ensuring scalable and maintainable code with enhanced reproducibility.\n\u2022MLOps Integration for Automated Workflow : Leveraged MLflow and DVC for experiment tracking and version \ncontrol, and utilized Azure CI/CD pipelines for automated deployment.\n\u2022Model Deployment with Docker and Flask : Deployed the deep learning model in a Dockerized Flask application, \noptimizing it for real-world usage and making it accessible via REST API, ensuring rapid and reliable inference.\nTransformer From Scratch In PyTorch: | PyTorch,Python,NLP\n\u2022Architecture: Implemented the full transformer architecture, including multi-head attention and feed-forward layers, \nusing PyTorch.\n\u2022Optimization: Optimized model performance through careful hyperparameter tuning and gradient clipping techniques.\n\u2022Performance: Achieved comparable results to pre-trained models on NLP tasks such as machine translation or text \nclassification.\nEDUCATION\nUniversity Of Engineering And Technology Peshawar\n\u2022 Bachelors of Science  -  Electrical Communication Engineering\n   GPA 3.0/4.0Sep\u00a02020 \u2013 Jul\u00a02024\nPeshawar, Pakistan\nEXPERIENCE\nMachine Learning Intern\nDigital Empowerment Pakistan\n\u2022Developed models using scikit-learn for classification and regression tasks. Utilized pandas \nfor data manipulation and Matplotlib for visualization.Aug\u00a02024 \u2013 Sep\u00a02024\nvirtual\n\u2022Applied TF-IDF and Bag-of-Words for feature extraction. Implemented text preprocessing \npipelines including tokenization, stemming, and stop word removal using NLTK and spaCy.\n\u2022Implemented CI/CD pipelines for ML models using GitHub Actions. Containerized \napplications with Docker and deployed on AWS/Azure. Monitored model performance and \ndata drift using MLflow.\nCERTIFICATES\nComplete Machine Learning,NLP Bootcamp MLOPS & Deployment(Udemy): \u00a0\u00a0\u00a0Learned key concepts in ML, NLP,\nand advanced topics like deep learning and transformers. Worked on real-world applications using TensorFlow, PyTorch, and\nscikit-learn. Gained experience in MLOps for model deployment and optimization, focusing on practical workflows and\nautomation.\n|\n|", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3268, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"1fe2137f-4d88-4026-923d-2090b6b3101b": {"node_ids": ["bc8b2cca-85cc-49de-879e-7c1930899b91"], "metadata": {"page_label": "1", "file_name": "Danyal-Alam-CV-Resume (2).pdf", "file_path": "d:\\GenAi\\QAsystem\\notebook\\..\\data\\Danyal-Alam-CV-Resume (2).pdf", "file_type": "application/pdf", "file_size": 108742, "creation_date": "2024-09-28", "last_modified_date": "2024-09-19"}}}}