{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_api_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GenAi\\QAsystem\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.core import ServiceContext\n",
    "\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-exp-0801\n",
      "models/gemini-1.5-pro-exp-0827\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-1.5-flash-002\n"
     ]
    }
   ],
   "source": [
    "for model in genai.list_models():\n",
    "    if 'generateContent' in model.supported_generation_methods:\n",
    "           \n",
    "     print(model.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = SimpleDirectoryReader('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = document.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danyal Alam\n",
      "danyalalam514@gmail.com 03175193965 linkedin.com/in/danyal-alam-272593312 \n",
      "github.com/Danyalalam \n",
      "SKILLS\n",
      "Languages — Python, SQL, HTML\n",
      "Frameworks — Tensorflow/Keras, PyTorch, Pandas, NumPy, NLTK\n",
      "MLOps — Git, Docker, MLflow, DVC, BentoML, CI/CD pipelines, GitHub Actions, RESTful APIs\n",
      "Cloud Technologies & Databases — Microsoft Azure, AWS  MySQL , MongoDB\n",
      "PROJECTS\n",
      "Production Grade Machine Learning Project: | MongoDB,AWS,Docker,Git,CI/CD,FastApi\n",
      "Visa Approval Prediction:\n",
      "•End-to-End Pipeline: Built a full machine learning pipeline from data ingestion (via MongoDB) to cloud deployment \n",
      "using Docker and AWS services (EC2, S3, ECR).\n",
      "•Model Management: Trained multiple models, evaluated them using Evidently AI for data drift detection, and pushed \n",
      "the best model to S3 for production.\n",
      "•CI/CD Integration: Implemented automated CI/CD workflows with GitHub Actions and Dockerized FastApi applicatoin \n",
      "for seamless deployment on AWS, ensuring scalability and reliability.\n",
      "End TO End Chest Cancer Classification with Mlops(DL): | CNN,Azure,CI/CD,Docker,Git,Flask\n",
      "•Developed An End-to-End Deep Learning Pipeline : Designed and implemented a modular pipeline for chest cancer \n",
      "detection using CNN, ensuring scalable and maintainable code with enhanced reproducibility.\n",
      "•MLOps Integration for Automated Workflow : Leveraged MLflow and DVC for experiment tracking and version \n",
      "control, and utilized Azure CI/CD pipelines for automated deployment.\n",
      "•Model Deployment with Docker and Flask : Deployed the deep learning model in a Dockerized Flask application, \n",
      "optimizing it for real-world usage and making it accessible via REST API, ensuring rapid and reliable inference.\n",
      "Transformer From Scratch In PyTorch: | PyTorch,Python,NLP\n",
      "•Architecture: Implemented the full transformer architecture, including multi-head attention and feed-forward layers, \n",
      "using PyTorch.\n",
      "•Optimization: Optimized model performance through careful hyperparameter tuning and gradient clipping techniques.\n",
      "•Performance: Achieved comparable results to pre-trained models on NLP tasks such as machine translation or text \n",
      "classification.\n",
      "EDUCATION\n",
      "University Of Engineering And Technology Peshawar\n",
      "• Bachelors of Science  -  Electrical Communication Engineering\n",
      "   GPA 3.0/4.0Sep 2020 – Jul 2024\n",
      "Peshawar, Pakistan\n",
      "EXPERIENCE\n",
      "Machine Learning Intern\n",
      "Digital Empowerment Pakistan\n",
      "•Developed models using scikit-learn for classification and regression tasks. Utilized pandas \n",
      "for data manipulation and Matplotlib for visualization.Aug 2024 – Sep 2024\n",
      "virtual\n",
      "•Applied TF-IDF and Bag-of-Words for feature extraction. Implemented text preprocessing \n",
      "pipelines including tokenization, stemming, and stop word removal using NLTK and spaCy.\n",
      "•Implemented CI/CD pipelines for ML models using GitHub Actions. Containerized \n",
      "applications with Docker and deployed on AWS/Azure. Monitored model performance and \n",
      "data drift using MLflow.\n",
      "CERTIFICATES\n",
      "Complete Machine Learning,NLP Bootcamp MLOPS & Deployment(Udemy):    Learned key concepts in ML, NLP,\n",
      "and advanced topics like deep learning and transformers. Worked on real-world applications using TensorFlow, PyTorch, and\n",
      "scikit-learn. Gained experience in MLOps for model deployment and optimization, focusing on practical workflows and\n",
      "automation.\n",
      "|\n",
      "|\n"
     ]
    }
   ],
   "source": [
    "print(doc[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_model = Gemini(model_name=\"models/gemini-pro\", api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_embed_model = GeminiEmbedding(model_name=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
